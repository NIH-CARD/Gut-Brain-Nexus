{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.5"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "### Importing packages", "metadata": {}, "id": "7c053810-7311-4420-8562-b721563763f1"}, {"cell_type": "code", "source": "%%capture\n%pip install lifelines\n%pip install statsmodels\n%pip install rpy2\n", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": [], "id": "33d4c83a-fa8c-4b7b-9b7f-fec5dd4caa51"}, {"cell_type": "code", "source": "import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport re\nimport math\nfrom lifelines import CoxPHFitter\nfrom statsmodels.stats.multitest import fdrcorrection\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport statsmodels.formula.api as smf\nimport rpy2.robjects as ro\nfrom rpy2.robjects import pandas2ri\npandas2ri.activate()\n\nro.r('install.packages(\"cmprsk\", repos=\"http://cran.r-project.org\")')\n\n# You may need this once per session:\n%load_ext rpy2.ipython", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": [], "id": "406c1c5c-d875-45c9-ab02-b94fbae4daab"}, {"cell_type": "markdown", "source": "### Cohort creation", "metadata": {}, "id": "28ee0dbd-680a-47d1-b606-51a7c2b48b78"}, {"cell_type": "code", "source": "PROJ_DIR = Path('/mnt/project/')\nDATA_DIR = PROJ_DIR / 'old_data'", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": [], "id": "05d06c96-e1dc-4bd0-a267-f880899cd2d0"}, {"cell_type": "code", "source": "#icd10 to definition conversion\nicd10_conversion = pd.read_csv(DATA_DIR / 'icd10_conversion_2.csv')\n\n\n# covariates such as date of birth, sex and townsend\ncovariates = pd.read_csv(DATA_DIR / 'f_covariate.csv')\ncovariates = covariates.drop(covariates.columns[0], axis=1)\n\n\n# PC table has the principal components 1,2,3,4,5\nPC = pd.read_csv(DATA_DIR / 'PCs.csv')\n\n\n# H_controls has the list of eids for the healthy participants\nH_controls = pd.read_csv(DATA_DIR / 'healthy_control_11_19_23.csv')\nH_controls = H_controls[[\"eid\"]].copy()\n\n\n# attending_info has the date of attending the assessment center, Year of birth and Age_at_recruitment\nattending_info = pd.read_csv(DATA_DIR / 'attennding_info.csv')\n# calculate the recruitement year for each participant:\n#By adding the year of birth to the age at recruitment, the operation effectively calculates the year in which each participant was recruited\nattending_info['recruit_year'] = attending_info['Year_of_birth'] + attending_info['Age_at_recruitment']\n\n\n# Death contains date of Date_of_death for participants\nDeath = pd.read_csv(DATA_DIR / 'Death_info.csv')\n\n\n#AD_PRS contains PRS score for participants (PRS includes the APOE allel)\nAD_PRS = pd.read_csv(DATA_DIR / 'AD_PRS_final.sscore',sep='\\t')\nAD_PRS.rename(columns={\"#FID\":\"eid\"},inplace = True)\n# AD_PRS_without_APOE prs score without APOE allele\nAD_PRS_without_APOE = pd.read_csv(DATA_DIR / 'AD_PRS_final_without_apoe.sscore',sep='\\t')\nAD_PRS_without_APOE.rename(columns={\"#FID\":\"eid\"},inplace = True)\n\n\n# APOE has the classification of E4E4 apoe for each participants\nAPOE = pd.read_csv(DATA_DIR / 'apoe_e4_designation.csv')\nAPOE.rename(columns={\"FID\":\"eid\"},inplace = True)\nAPOE.drop(columns = ['IID'], inplace = True)\n\n\n#df_icd10 has 158 icd10 codes for digestive, endocrine and metabolic disorders\ndf_icd10 = pd.read_csv(DATA_DIR / 'f_icd10.csv')\ndf_icd10 = df_icd10.drop(df_icd10.columns[0], axis=1)\n\n## dataframe for F00 data\ndf_f00 = pd.read_csv(DATA_DIR / 'F00.csv')\n#add df_f00 to the table\ndf_icd10  = pd.merge(df_icd10 , df_f00[[\"eid\",\"p130836\"]], on = \"eid\")\n# Replace NaN in 'p131036' with values from 'p130836' only where 'p130836' is not NaN and 'p131036' is NaN\ndf_icd10.loc[df_icd10['p130836'].notna() & df_icd10['p131036'].isna(), 'p131036'] = df_icd10['p130836']\ndf_icd10.drop('p130836', axis=1, inplace=True)\n\n\n# add the data set for the european descends\neuropean = pd.read_csv(DATA_DIR / 'Genetic_relatedness_pairing.csv')\n# p22006 data field shows if the person is Caucasian or not , 1 means the person is Caucasian.\n# filter out only the one who have p22006 equal to 1\n#only keep european individuals p22006 =1\neid_list = european[european['p22006'] == 1]['eid'].tolist()\n\n\n#related individuals information:\nrelatedness = pd.read_csv(PROJ_DIR / 'Bulk/Genotype Results/Genotype calls/ukb_rel.dat', sep=' ')\n# this file only has the related individuals. so we just remove them at the 3rd-degree relationships\nrel_remove = relatedness[relatedness['Kinship']> 0.0884]\nrel_remove.info()\n# remove the first column ID1 formt the ICD10 data set\neids_to_remove = rel_remove[\"ID1\"].tolist()\n\n\ndf_icd10 = df_icd10[df_icd10['eid'].isin(eid_list)]\ndf_icd10 = df_icd10[~df_icd10['eid'].isin(eids_to_remove)]\n\n\n# convert the covariates codes to meaningful names\ncovariate_conversio = {'p21022' :\"Age_at_recruitment\", \"p34\" : \"Year_of_birth\", \"p52\" : 'Month_of_birth', 'p31' : \"sex\", 'p22189' :'Townsend_deprivation_index'}\ncovariates = covariates.rename(columns=covariate_conversio)", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": [], "id": "4f32008d-3059-4cae-835d-c930d88d184d"}, {"cell_type": "markdown", "source": "***\nThe recruitment year will be considered as the start date of the study for each participant.\nThe end of the study for a participant will be determined by either the onset of AD (Alzheimer's Disease), death, or the date '2023-01-01'\nwhichever comes first.\n***", "metadata": {"tags": []}, "id": "dc218d2d-80d3-4dc4-a1fd-8e0cbb3e1e2b"}, {"cell_type": "code", "source": "#alzheimer's 131036\n#parkinson's disease 131022\n\n# Keep only non-related Europeans from controls and add icd10 info\nH_controls = H_controls[H_controls['eid'].isin(eid_list)]\nH_controls = H_controls[~H_controls['eid'].isin(eids_to_remove)]\nH_controls = H_controls.merge(df_icd10, on='eid')\n\n# Copy the data set\nAD_merged_data = df_icd10.copy()\n\n## only AD cases\n# Remove rows where column 'p131036' has value 0\nAD_merged_data = AD_merged_data[~AD_merged_data['p131036'].isna()]\n\n# Create a table including the columns for the year of recruitment, the date of Alzheimer's Disease diagnosis (p131036), and the date of death.\nattending_info = attending_info[['eid','recruit_year']]\ndf = AD_merged_data[['eid','p131036']]\nH_controls = H_controls[['eid','p131036']]\n\n# Concatenate the DataFrames on top of each other\ndf = pd.concat([df, H_controls], ignore_index=True)\ndf = pd.merge(df, attending_info, on='eid')\nDeath = Death[['eid','p40000_i0_Date_of_death']]\ndf = pd.merge(Death, df, on='eid', how='right')\n\n# Convert date columns to datetime\ndf['p40000_i0_Date_of_death'] = pd.to_datetime(df['p40000_i0_Date_of_death'])\ndf['p131036'] = pd.to_datetime(df['p131036'])\n\n# Set study end date to Jan 1, 2023\nstudy_end = pd.Timestamp('2023-01-01')\n\n# Define stop date: earliest of AD, death, or study end\ndf['stop'] = df[['p131036', 'p40000_i0_Date_of_death']].min(axis=1)\ndf['stop'] = df['stop'].fillna(study_end)\n\n# Keep original full stop date (if needed)\ndf['complete_stop_date'] = df['stop']\n\n# Set start = recruit year\ndf.rename(columns={'recruit_year': 'start'}, inplace=True)\n\n# Extract year from datetime columns\ndf['stop'] = df['stop'].dt.year\ndf['p131036_year'] = df['p131036'].dt.year\n\n# Drop invalid entries: stop before start\ndf = df[df['stop'] > df['start']]\n\n# Drop rows where AD happened before recruitment\ndf = df[(df['start'] <= df['p131036_year']) | df['p131036_year'].isna()]\ndf[(df['p131036_year'].isna()) | (df['p131036_year'] <= df['stop'])]\n\n# Calculate duration\ndf['duration'] = np.where(\n    df['p131036_year'].isnull(),\n    df['stop'] - df['start'],\n    df['p131036_year'] - df['start']\n)\n\n# Define event_type for Fine and Gray\n# 0 = censored, 1 = AD, 2 = death before AD\ndf['event_type'] = 0\ndf.loc[df['p131036'].notna(), 'event_type'] = 1\ndf.loc[df['p131036'].isna() & df['p40000_i0_Date_of_death'].notna(), 'event_type'] = 2\n\n#add the prs values to the table\ndf = pd.merge(df, AD_PRS[[\"eid\",\"SCORE1_AVG\"]], on = \"eid\")  \n\ndf = pd.merge(df, AD_PRS_without_APOE[[\"eid\",\"SCORE1_AVG\"]], on = \"eid\")  \n\n# Calculate mean and SD for controls (where event == 0)\nmean_controls = df[\"SCORE1_AVG_x\"][df[\"event_type\"] == 0].mean()\nsd_controls = df[\"SCORE1_AVG_x\"][df[\"event_type\"] == 0].std()\n\n# Compute the z-score for SCORE1_AVG\ndf[\"zSCORE\"] = (df[\"SCORE1_AVG_x\"] - mean_controls) / sd_controls\n\n# Calculate mean and SD for controls (where event == 0)\nmean_controls = df[\"SCORE1_AVG_y\"][df[\"event_type\"] == 0].mean()\nsd_controls = df[\"SCORE1_AVG_y\"][df[\"event_type\"] == 0].std()\n\n# Compute the z-score for SCORE1_AVG\ndf[\"zSCORE_without_apoe\"] = (df[\"SCORE1_AVG_y\"] - mean_controls) / sd_controls\n\n# get the list of icd10 codes\nlist_of_icd10 = df_icd10.columns.tolist()[1:]\n# remove pd and ad\nlist_of_icd10.remove(\"p131022\")\nlist_of_icd10.remove(\"p131036\")\n\ncutoff_date = pd.to_datetime(\"1999-01-01\")\n\n# Load your preprocessed df, df_icd10, PC, APOE, and covariates\n# Example:\n# df = pd.read_csv(\"df.csv\")\n# df_icd10 = pd.read_csv(\"df_icd10.csv\")\n# PC = pd.read_csv(\"PC.csv\")\n# APOE = pd.read_csv(\"APOE.csv\")\n# covariates = pd.read_csv(\"covariates.csv\")\n\n# list_of_icd10 = ['p130008', 'p130010', ...]", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "a4dd8fa0-62a9-4af5-aef9-0403766dbb3f"}, {"cell_type": "code", "source": "dic_fg_results = {}\ncutoff_date = pd.Timestamp(\"1999-01-01\")\n\n\nfor var in list_of_icd10:\n\n    print(f\"Running Fine-Gray for {var}\")\n    \n    try:\n        # Merge all required data\n        t = pd.merge(df[[\"eid\", \"duration\", \"event_type\", \"p131036\", \"start\"]],\n                     df_icd10[[\"eid\", var]], on=\"eid\")\n        t = pd.merge(t, covariates[[\"eid\", \"Age_at_recruitment\", \"Townsend_deprivation_index\", \"sex\"]], on=\"eid\")\n        t = pd.merge(t, PC, on=\"eid\")\n        t = pd.merge(t, APOE[[\"eid\", \"e4_copies\"]], on=\"eid\")\n\n        # # Calculate age at recruitment\n        # t[\"Age_at_recruitment\"] = t[\"start\"] - t[\"Year_of_birth\"]\n\n        # Convert and filter dates\n        t[\"p131036\"] = pd.to_datetime(t[\"p131036\"])\n        t[var] = pd.to_datetime(t[var])\n        t = t[~(t[var] < cutoff_date)]\n        t = t[~(t[\"p131036\"] < cutoff_date)]\n\n        # ICD10 after AD \u2192 NaT\n        t.loc[t[var] >= t[\"p131036\"], var] = pd.NaT\n\n        # Binary ICD10 presence\n        t[var] = (~t[var].isna()).astype(int)\n\n        # Skip if too few cases or AD events\n        if t[var].sum() < 3 or t[t[var] == 1][\"event_type\"].eq(1).sum() <= 1:\n            print(f\"Skipping {var} (too few cases)\")\n            continue\n\n        # Select columns\n        cols = [\"duration\", \"event_type\", var, \"Age_at_recruitment\", \"sex\", \"Townsend_deprivation_index\",\n                \"p22009_a1\", \"p22009_a2\", \"p22009_a3\", \"p22009_a4\", \"p22009_a5\"]\n        t_r = t[cols].dropna().copy()\n\n        # Push to R\n        ro.globalenv[\"r_df\"] = pandas2ri.py2rpy(t_r)\n        ro.globalenv[\"covariate_cols\"] = ro.StrVector(cols[2:])\n\n        # Run Fine-Gray in R\n        res = ro.r('''\n            library(cmprsk)\n            f <- as.formula(paste(\"~\", paste(covariate_cols, collapse = \" + \")))\n            X <- model.matrix(f, data = r_df)[, -1]\n            X <- X[, qr(X)$pivot[1:qr(X)$rank]]\n            fg_model <- crr(\n                ftime = r_df$duration,\n                fstatus = r_df$event_type,\n                cov1 = X,\n                failcode = 1,\n                cencode = 0\n            )\n            z_scores <- fg_model$coef / sqrt(diag(fg_model$var))\n            p_vals <- 2 * (1 - pnorm(abs(z_scores)))\n            log10p <- -log10(p_vals)\n            list(\n                coef = fg_model$coef,\n                se = sqrt(diag(fg_model$var)),\n                z = z_scores,\n                p = p_vals,\n                HR = exp(fg_model$coef),\n                CI_lower = exp(fg_model$coef - 1.96 * sqrt(diag(fg_model$var))),\n                CI_upper = exp(fg_model$coef + 1.96 * sqrt(diag(fg_model$var))),\n                log10p = log10p\n            )\n        ''')\n\n        # Save results\n        dic_fg_results[var] = {\n            \"coef\": np.array(res.rx2('coef'))[0],\n            \"HR\": np.array(res.rx2('HR'))[0],\n            \"se\": np.array(res.rx2('se'))[0],\n            \"z\": np.array(res.rx2('z'))[0],\n            #\"p\": float(res.rx2('p')[0]),\n            \"p\": \"{:.16e}\".format(res.rx2('p')[0]),\n            \"log10_p\": float(res.rx2('log10p')[0]),\n            \"CI_lower\": np.array(res.rx2('CI_lower'))[0],\n            \"CI_upper\": np.array(res.rx2('CI_upper'))[0],\n            \"N\": t_r.shape[0],\n            \"N_pairs\": int(((t_r[var] == 1) & (t_r[\"event_type\"] == 1)).sum())\n        }\n\n    except Exception as e:\n        print(f\"Error in {var}: {e}\")\n", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "07e8a810-a232-4658-a937-c5a363c44760"}, {"cell_type": "code", "source": "# Build summary table for Fine-Gray model\npd_table_fg = {}\n\nfor var, res in dic_fg_results.items():\n    if var[1:] not in icd10_conversion:\n        continue  # Skip if not in mapping\n\n    name = icd10_conversion[var[1:]][1]\n    code = icd10_conversion[var[1:]][0]\n\n    pd_table_fg[name] = [\n        var,\n        code,\n        \"AD\",\n        name,\n        res['HR'][0] if isinstance(res['HR'], (list, np.ndarray)) else res['HR'],\n        res['CI_lower'][0] if isinstance(res['CI_lower'], (list, np.ndarray)) else res['CI_lower'],\n        res['CI_upper'][0] if isinstance(res['CI_upper'], (list, np.ndarray)) else res['CI_upper'],\n        res['p'],  # scientific notation string\n        res['log10_p'],              # added field\n        res['N_pairs'],\n        res['N']\n    ]\n    \noutput_fg = pd.DataFrame.from_dict(\n    pd_table_fg,\n    orient='index',\n    columns=('code', 'ICD10_CODE', 'NDD', 'Description', 'HR', 'ci_min', 'ci_max', 'P_VAL','log10_p', 'N_pairs', 'n')\n)\n\n# Convert p-values to float\np_values = output_fg['P_VAL'].astype(float).values\n\n# Apply FDR correction\nrejected, pvals_corrected = fdrcorrection(p_values)\n\n# Add corrected p-values to the dataframe\noutput_fg['P_VAL_FDR_CORRECTED'] = pvals_corrected\n\noutput_fg.to_csv(\"fg_results.csv\", index=False)", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "b8d5824a-61f8-4cb1-8212-0b0fb9a57724"}, {"cell_type": "code", "source": "output_fg", "metadata": {}, "execution_count": null, "outputs": [], "id": "430cea7a-a6a4-4d09-83eb-432ed4765f8b"}, {"cell_type": "markdown", "source": "## Importing packages", "metadata": {}, "id": "c111d787-5133-438f-9a7d-4f1185bcc7cd"}, {"cell_type": "code", "source": "#icd10 to definition conversion\nicd10_conversion = pd.read_csv(\"/mnt/project/aug/icd10_conversion.csv\")\n\n# covariates such as date of birth, sex and townsend\ncovariates = pd.read_csv(\"/mnt/project/aug/f_covariate.csv\")\ncovariates = covariates.drop(covariates.columns[0], axis=1)\n\n# PC table has the principal components 1,2,3,4,5\nPC = pd.read_csv('/mnt/project/PCs.csv')\n# H_controls has the list of eids for the healthy participants\nH_controls = pd.read_csv('/mnt/project/healthy_control_11_19_23.csv')\nH_controls =H_controls[[\"eid\"]].copy()\n\n# attending_info has the date of attending the assessment center, Year of birth and Age_at_recruitment\nattending_info = pd.read_csv(\"/mnt/project/attennding_info.csv\")\n\n# Death contains date of Date_of_death for participants\nDeath = pd.read_csv(\"/mnt/project/Death_info.csv\")\n\n# PRS values for PD\nPD_PRS = pd.read_csv(\"/mnt/project/PD_PRS/PD_PRS_final.sscore\",sep= \"\\t\")\n\n# lrkk2 classification\nlrkk2 = pd.read_csv(\"/mnt/project/lrkk2_carriers.csv\")\nlrkk2.rename(columns={'FID':'eid','12:40220632_C': 'C_12_40220632', '12:40340400_G':'G_12_40340400'},inplace = True)\n\n# GBA1 classification\nGBA1 = pd.read_csv(\"/mnt/project/GBA1_carriers.csv\")\nGBA1.rename(columns={'FID':'eid','1:155162560_G': 'G_1_155162560', '1:155235843_T': 'T_1_155235843'}, inplace =True)\n\n#df_icd10 has 158 icd10 codes for digestive, endocrine and metabolic disorders\ndf_icd10 = pd.read_csv(\"/mnt/project/aug/f_icd10.csv\")\ndf_icd10 = df_icd10.drop(df_icd10.columns[0], axis=1)", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "14b09b45-fc70-4bc8-bd89-3b90a7db5aa6"}, {"cell_type": "code", "source": "icd10_conversion2 = pd.read_csv(\"/mnt/project/old_data/icd10_conversion_2.csv\")\n\nicd10_conversion2.head()", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": [], "id": "851abf5c-7494-420f-b105-8a4dcea2b465"}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": [], "id": "1f30f61f-030e-4412-90e3-486e27b8dde9"}, {"cell_type": "code", "source": "df_icd10", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "654fed8a-4235-4ba9-bbc6-c93d355b05c1"}, {"cell_type": "code", "source": "#add the data set for the european descends\n#p22006 data field is shows if the person is Caucasian or not , 1 means the person is Caucasian.\n# filter out only the one who have p22006 equal to 1\neuropean = pd.read_csv('/mnt/project/Genetic relatedness pairing.csv')\n\n# p22006 data field shows if the person is Caucasian or not , 1 means the person is Caucasian.\n# filter out only the one who have p22006 equal to 1\n#only keep european individuals p22006 =1\neid_list = european[european['p22006'] == 1]['eid'].tolist()\n\ndf_icd10 = df_icd10[df_icd10['eid'].isin(eid_list)]\n\n#relatedness information:\nrelatedness = pd.read_csv('/mnt/project/Bulk/Genotype Results/Genotype calls/ukb_rel.dat', sep = ' ')\n\n# this file only has the related individuals. so we just remove them at the 3rd-degree relationships\nrel_remove = relatedness[relatedness['Kinship']> 0.0884]\nrel_remove.info()\n\n# remove the first column ID1 formt the ICD10 data set\neids_to_remove = rel_remove[\"ID1\"].tolist()\ndf_icd10 = df_icd10[~df_icd10['eid'].isin(eids_to_remove)]\n\n# rename the FID column\nPD_PRS.rename(columns={\"#FID\":\"eid\"},inplace = True)\n\n# calculate the recruitement year for each participant:\n#By adding the year of birth to the age at recruitment, the operation effectively calculates the year in which each participant was recruited\nattending_info['recruit_year'] = attending_info['Year_of_birth'] + attending_info['Age_at_recruitment']", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "986c40b5-e1a5-4250-b8b2-9952c5046d79"}, {"cell_type": "markdown", "source": "***\nThe recruitment year will be considered as the start date of the study for each participant.\nThe end of the study for a participant will be determined by either the onset of AD (Alzheimer's Disease), death, or the date '2023-01-01'\nwhichever comes first.\n***", "metadata": {"tags": []}, "id": "97de1c81-1ffe-47a3-b797-00eecaf35270"}, {"cell_type": "code", "source": "# convert the covariates codes to meaningful names\ncovariate_conversio = {'p21022' :\"Age_at_recruitment\", \"p34\" : \"Year_of_birth\", \"p52\" : 'Month_of_birth', 'p31' : \"sex\", 'p22189' :'Townsend_deprivation_index'}\ncovariates = covariates.rename(columns=covariate_conversio)", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "23061db3-262c-4580-b45d-94c51e5c3597"}, {"cell_type": "code", "source": "#alzheimer's 131036\n#parkinson's disease 131022\n\n#only keep Europeans in the control files:\nH_controls = H_controls[H_controls['eid'].isin(eid_list)]\n#remove the related individuals form the control file:\nH_controls = H_controls[~H_controls['eid'].isin(eids_to_remove)]\n#add the icd10 information to healthy data frame\nH_controls = H_controls.merge(df_icd10, on='eid')", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "cc6fe8e2-aa2a-4536-bcb9-6f84e7344e08"}, {"cell_type": "code", "source": "# copy the data set\nPD_merged_data  =  df_icd10.copy()\n\n## only AD cases\n# Remove rows where column 'p131036' has value 0\nPD_merged_data = PD_merged_data[~PD_merged_data['p131022'].isna()]\n", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "525ba9cb-3463-4f86-ae76-7775f2be4015"}, {"cell_type": "code", "source": "\n# Create a table including the columns for the year of recruitment, the date of Alzheimer's Disease diagnosis (p131036), and the date of death.\n\nattending_info = attending_info[['eid','recruit_year']]\ndf = PD_merged_data[['eid','p131022']]\nH_controls = H_controls[['eid','p131022']]\n# Concatenate the DataFrames on top of each other\ndf = pd.concat([df, H_controls], ignore_index=True)\ndf = pd.merge(df, attending_info, on='eid')\nDeath = Death[['eid','p40000_i0_Date_of_death']]\ndf = pd.merge(Death, df, on='eid', how='right')", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "883a27d2-fb94-44e9-901d-bf47b21b1011"}, {"cell_type": "code", "source": "df", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "7cd3ba1c-97d4-417a-960e-7a78f43d1e46"}, {"cell_type": "code", "source": "# Convert date columns to datetime\ndf['p40000_i0_Date_of_death'] = pd.to_datetime(df['p40000_i0_Date_of_death'])\ndf['p131022'] = pd.to_datetime(df['p131022'])", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "91003ea8-1f44-4a33-a5e5-119d683b60f6"}, {"cell_type": "code", "source": "# Set study end date to Jan 1, 2023\nstudy_end = pd.Timestamp('2023-01-01')", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "19c88319-7b5c-4ebb-afc7-dcf60021afac"}, {"cell_type": "code", "source": "# Define stop date: earliest of AD, death, or study end\ndf['stop'] = df[['p131022', 'p40000_i0_Date_of_death']].min(axis=1)\ndf['stop'] = df['stop'].fillna(study_end)", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "0fc11065-3f7d-4460-b6a2-3e2c0e02a8a3"}, {"cell_type": "code", "source": "# Keep original full stop date (if needed)\ndf['complete_stop_date'] = df['stop']", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "49207bb4-b5d0-48cf-8973-108952f2c0fe"}, {"cell_type": "code", "source": "# Set start = recruit year\ndf.rename(columns={'recruit_year': 'start'}, inplace=True)", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "49bf0a1e-d80e-4f78-af50-be8ddb8b59b3"}, {"cell_type": "code", "source": "\n# Extract year from datetime columns\ndf['stop'] = df['stop'].dt.year\ndf['p131022_year'] = df['p131022'].dt.year", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "e40fbb72-2388-4a27-a512-f4866db62c25"}, {"cell_type": "code", "source": "df", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "6ee7c046-025c-4d71-ae3e-84134ec9fcba"}, {"cell_type": "code", "source": "\n# Drop invalid entries: stop before start\ndf = df[df['stop'] > df['start']]", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "f742c1e0-b38a-4df0-8d96-e71fdca7dbcb"}, {"cell_type": "code", "source": "# Drop rows where AD happened before recruitment\ndf = df[(df['start'] <= df['p131022_year']) | df['p131022_year'].isna()]", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "078cf519-5c20-49b1-abd6-cb36f50d4642"}, {"cell_type": "code", "source": "df[(df['p131022_year'].isna()) | (df['p131022_year'] <= df['stop'])]\n", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "948a408e-b031-42a9-82ae-dad5434837c4"}, {"cell_type": "code", "source": "\n# Calculate duration\ndf['duration'] = np.where(\n    df['p131022_year'].isnull(),\n    df['stop'] - df['start'],\n    df['p131022_year'] - df['start']\n)\n", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "d69db497-9ac8-4882-ab9f-0758e1dfdc9b"}, {"cell_type": "code", "source": "# Define event_type for Fine and Gray\n# 0 = censored, 1 = PD, 2 = death before PD\ndf['event_type'] = 0\ndf.loc[df['p131022'].notna(), 'event_type'] = 1\ndf.loc[df['p131022'].isna() & df['p40000_i0_Date_of_death'].notna(), 'event_type'] = 2", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "50b0c35e-b8de-42d2-8f55-15440ea6d685"}, {"cell_type": "code", "source": "#add the prs values to the table\ndf = pd.merge(df, PD_PRS[[\"eid\",\"SCORE1_AVG\"]], on = \"eid\")  \n\n", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "16eb8adc-21c6-450b-9921-908b236d9d97"}, {"cell_type": "code", "source": "# Calculate mean and SD for controls (where event == 0)\nmean_controls = df[\"SCORE1_AVG\"][df[\"event_type\"] == 0].mean()\nsd_controls = df[\"SCORE1_AVG\"][df[\"event_type\"] == 0].std()\n\n# Compute the z-score for SCORE1_AVG\ndf[\"zSCORE\"] = (df[\"SCORE1_AVG\"] - mean_controls) / sd_controls\n\n", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "73e6284d-aa64-4754-b5ab-e0b6fb30ce54"}, {"cell_type": "code", "source": "# get the list of icd10 codes\nlist_of_icd10 = df_icd10.columns.tolist()[1:]\n# remove pd and ad\nlist_of_icd10.remove(\"p131022\")\nlist_of_icd10.remove(\"p131036\")\n", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "72a0279a-e673-4175-b4f2-e20b8c536c83"}, {"cell_type": "code", "source": "cutoff_date = pd.to_datetime(\"1999-01-01\")\n\n# Load your preprocessed df, df_icd10, PC, APOE, and covariates\n# Example:\n# df = pd.read_csv(\"df.csv\")\n# df_icd10 = pd.read_csv(\"df_icd10.csv\")\n# PC = pd.read_csv(\"PC.csv\")\n# APOE = pd.read_csv(\"APOE.csv\")\n# covariates = pd.read_csv(\"covariates.csv\")\n\n# list_of_icd10 = ['p130008', 'p130010', ...]", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "e28d6737-3381-4786-a375-f36f450cae18"}, {"cell_type": "code", "source": "dic_fg_results = {}\ncutoff_date = pd.Timestamp(\"1999-01-01\")\n\n\nfor var in list_of_icd10:\n\n    print(f\"Running Fine-Gray for {var}\")\n    \n    try:\n        # Merge all required data\n        t = pd.merge(df[[\"eid\", \"duration\", \"event_type\", \"p131022\", \"start\"]],\n                     df_icd10[[\"eid\", var]], on=\"eid\")\n        t = pd.merge(t, covariates[[\"eid\", \"Age_at_recruitment\", \"Townsend_deprivation_index\", \"sex\"]], on=\"eid\")\n        t = pd.merge(t, PC, on=\"eid\")\n        \n\n        # # Calculate age at recruitment\n        # t[\"Age_at_recruitment\"] = t[\"start\"] - t[\"Year_of_birth\"]\n\n        # Convert and filter dates\n        t[\"p131022\"] = pd.to_datetime(t[\"p131022\"])\n        t[var] = pd.to_datetime(t[var])\n        t = t[~(t[var] < cutoff_date)]\n        t = t[~(t[\"p131022\"] < cutoff_date)]\n\n        # ICD10 after AD \u2192 NaT\n        t.loc[t[var] >= t[\"p131022\"], var] = pd.NaT\n\n        # Binary ICD10 presence\n        t[var] = (~t[var].isna()).astype(int)\n\n        # Skip if too few cases or AD events\n        if t[var].sum() < 3 or t[t[var] == 1][\"event_type\"].eq(1).sum() <= 1:\n            print(f\"Skipping {var} (too few cases)\")\n            continue\n\n        # Select columns\n        cols = [\"duration\", \"event_type\", var, \"Age_at_recruitment\", \"sex\", \"Townsend_deprivation_index\",\n                \"p22009_a1\", \"p22009_a2\", \"p22009_a3\", \"p22009_a4\", \"p22009_a5\"]\n        t_r = t[cols].dropna().copy()\n\n        # Push to R\n        ro.globalenv[\"r_df\"] = pandas2ri.py2rpy(t_r)\n        ro.globalenv[\"covariate_cols\"] = ro.StrVector(cols[2:])\n\n        # Run Fine-Gray in R\n        res = ro.r('''\n            library(cmprsk)\n            f <- as.formula(paste(\"~\", paste(covariate_cols, collapse = \" + \")))\n            X <- model.matrix(f, data = r_df)[, -1]\n            X <- X[, qr(X)$pivot[1:qr(X)$rank]]\n            fg_model <- crr(\n                ftime = r_df$duration,\n                fstatus = r_df$event_type,\n                cov1 = X,\n                failcode = 1,\n                cencode = 0\n            )\n            z_scores <- fg_model$coef / sqrt(diag(fg_model$var))\n            p_vals <- 2 * (1 - pnorm(abs(z_scores)))\n            log10p <- -log10(p_vals)\n            list(\n                coef = fg_model$coef,\n                se = sqrt(diag(fg_model$var)),\n                z = z_scores,\n                p = p_vals,\n                HR = exp(fg_model$coef),\n                CI_lower = exp(fg_model$coef - 1.96 * sqrt(diag(fg_model$var))),\n                CI_upper = exp(fg_model$coef + 1.96 * sqrt(diag(fg_model$var))),\n                log10p = log10p\n            )\n        ''')\n\n        # Save results\n        dic_fg_results[var] = {\n            \"coef\": np.array(res.rx2('coef'))[0],\n            \"HR\": np.array(res.rx2('HR'))[0],\n            \"se\": np.array(res.rx2('se'))[0],\n            \"z\": np.array(res.rx2('z'))[0],\n            #\"p\": float(res.rx2('p')[0]),\n            \"p\": \"{:.16e}\".format(res.rx2('p')[0]),\n            \"log10_p\": float(res.rx2('log10p')[0]),\n            \"CI_lower\": np.array(res.rx2('CI_lower'))[0],\n            \"CI_upper\": np.array(res.rx2('CI_upper'))[0],\n            \"N\": t_r.shape[0],\n            \"N_pairs\": int(((t_r[var] == 1) & (t_r[\"event_type\"] == 1)).sum())\n        }\n\n    except Exception as e:\n        print(f\"Error in {var}: {e}\")\n", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "97253cda-ae8e-4ef9-aa2d-d45f154b27df"}, {"cell_type": "code", "source": "# Build summary table for Fine-Gray model\npd_table_fg = {}\n\nfor var, res in dic_fg_results.items():\n    if var[1:] not in icd10_conversion:\n        continue  # Skip if not in mapping\n\n    name = icd10_conversion[var[1:]][1]\n    code = icd10_conversion[var[1:]][0]\n\n    pd_table_fg[name] = [\n        var,\n        code,\n        \"PD\",\n        name,\n        res['HR'][0] if isinstance(res['HR'], (list, np.ndarray)) else res['HR'],\n        res['CI_lower'][0] if isinstance(res['CI_lower'], (list, np.ndarray)) else res['CI_lower'],\n        res['CI_upper'][0] if isinstance(res['CI_upper'], (list, np.ndarray)) else res['CI_upper'],\n        res['p'],  # scientific notation string\n        res['log10_p'],              # added field\n        res['N_pairs'],\n        res['N']\n    ]\n\n    \noutput_fg = pd.DataFrame.from_dict(\n    pd_table_fg,\n    orient='index',\n    columns=('code', 'ICD10_CODE', 'NDD', 'Description', 'HR', 'ci_min', 'ci_max', 'P_VAL','log10_p', 'N_pairs', 'n')\n)\n\n# Convert p-values to float\np_values = output_fg['P_VAL'].astype(float).values\n\n# Apply FDR correction\nrejected, pvals_corrected = fdrcorrection(p_values)\n\n# Add corrected p-values to the dataframe\noutput_fg['P_VAL_FDR_CORRECTED'] = pvals_corrected\n\noutput_fg.to_csv(\"fg_PD_results.csv\", index=False)", "metadata": {"tags": []}, "execution_count": null, "outputs": [], "id": "46764894-147b-48d7-921d-d137dcd0820e"}]}